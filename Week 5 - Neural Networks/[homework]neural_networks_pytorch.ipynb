{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"[homework]neural_networks_pytorch.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"BsP8X727kQMe","colab_type":"text"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\"  width=400></p>\n","\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>\n","\n","# Домашнее задание. Обучение нейронных сетей на PyTorch.\n","\n","В этом домашнем задании вам предстоит предсказывать типы небесных объектов. Эту задачу вы будете решать с помощью нейронных сетей, используя библиотеку PyTorch. \n","\n","Вам необходимо заполнить пропуски в ноутбуке. Кое-где вас просят сделать выводы о проделанной работе. Постарайтесь ответить на вопросы обдуманно и развёрнуто. \n","\n","\n","***В этом домашнем задании мы используем новый метод проверки --- Peer Review.***\n","\n","Peer Review — альтернативный способ проверки ваших заданий, который подразумевает, что после сдачи задания у вас появится возможность (и даже моральная обязанность, но не строгое обязательство) проверить задания нескольких ваших однокурсников. Соответственно, и ваши работы будут проверять другие учащиеся курса. Для выставления оценки необходимо будет, чтобы вашу работу проверило по крайней мере 3 ваших однокурсника. Вы же, выступая в роли проверяющего, сможете узнать больше о выполненном задании, увидеть, как его выполняли другие. \n","\n","Чем больше заданий однокурсников вы проверите, тем лучше! Но, пожалуйста, проверяйте внимательно. По нашим оценкам, на проверку одной работы у вас уйдёт 5-10 минут. Подробные инструкции для проверки заданий мы пришлём позже.\n","\n","***ВАЖНО!*** Чтобы задание было удобнее проверять, необходимо сдать на Stepik два файла: файл в формате .ipynb и файл в формате .pdf. Файл .pdf можно получить, открыв File->Print и выбрать \"Save as PDF\". Аналогичный способ есть и в Jupyter.\n"]},{"cell_type":"code","metadata":{"id":"p-2rBvEkkQMj","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","from torch import functional as F\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PHc7UePMkQMp","colab_type":"text"},"source":["# Дисклеймер про CrossEntropyLoss и NLLLoss\n","\n","Обычно в PyTorch не нужно делать Softmax как последний слой модели. \n","\n","* Если Вы используете NLLLoss, то ему на вход надо давать лог вероятности, то есть выход слоя LogSoftmax. (Просто результат софтмакса, к которому применен логарифм)\n","* Если Вы используете CrossEntropyLoss, то применение LogSoftmax уже включено внутрь лосса, поэтому ему на вход надо подавать просто выход обычного линейного слоя без активации. По сути CrossEntropyLoss = LogSoftmax + NLLLoss\n","\n","Зачем такие сложности, чтобы посчитать обычную кросс энтропию, которую мы использовали как лосс еще в логистической регрессии? Дело в том, что нам в любом случае придется взять логарифм от результатов софтмакса, а если делать это одной функцией, то можно сделать более устойчивую реализацию, которая даст меньшую вычислительную погрешность. \n","\n","Таким образом, если у вас в конце сети, решающей задачу классификации, стоит просто линейный слой без активации, то вам нужно использовать CrossEntropy. В этой домашке везде используется лосс CrossEntropy"]},{"cell_type":"markdown","metadata":{"id":"8rM9IY0YkQMq","colab_type":"text"},"source":["# Задание 1. Создайте генератор батчей. \n","\n","В этот раз мы хотим сделать генератор, который будет максимально похож на то, что используется в реальном обучении. \n","\n","С помощью numpy вам нужно перемешать исходную выборку и выбирать из нее батчи размером batch_size, если размер выборки не делился на размер батча, то последний батч должен иметь размер меньше batch_size и состоять просто из всех оставшихся объектов. Возвращать нужно в формате (X_batch, y_batch). Необходимо написать именно генератор, то есть вместо return использовать yield. \n","\n","Хорошая статья про генераторы: https://habr.com/ru/post/132554/\n","\n","\n","**Ответ на задание - код**\n"]},{"cell_type":"code","metadata":{"id":"ttf6PZuVkQMr","colab_type":"code","colab":{}},"source":["def batch_generator(X, y, batch_size):\n","    np.random.seed(42)\n","    perm = np.random.permutation(len(X))\n","    \n","    # YOUR CODE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2RvSIsl-c5lW","colab_type":"text"},"source":["Попробуем потестировать наш код"]},{"cell_type":"code","metadata":{"id":"U_snYtUUcpDy","colab_type":"code","colab":{}},"source":["from inspect import isgeneratorfunction\n","assert isgeneratorfunction(batch_generator), \"batch_generator должен быть генератором! В условии есть ссылка на доки\"\n","\n","X = np.array([\n","              [1, 2, 3],\n","              [4, 5, 6],\n","              [7, 8, 9]\n","])\n","y = np.array([\n","              1, 2, 3\n","])\n","\n","# Проверим shape первого батча\n","iterator = batch_generator(X, y, 2)\n","X_batch, y_batch = next(iterator)\n","assert X_batch.shape == (2, 3), y_batch.shape == (2,)\n","assert np.allclose(X_batch, X[:2]), np.allclose(y_batch, y[:2])\n","\n","# Проверим shape последнего батча (их всего два)\n","X_batch, y_batch = next(iterator)\n","assert X_batch.shape == (1, 3), y_batch.shape == (1,)\n","assert np.allclose(X_batch, X[2:]), np.allclose(y_batch, y[2:])\n","\n","# Проверим, что итерации закончились\n","iter_ended = False\n","try:\n","    next(iterator)\n","except StopIteration:\n","    iter_ended = True\n","assert iter_ended\n","\n","# Еще раз проверим то, сколько батчей создает итератор\n","X = np.random.randint(0, 100, size=(1000, 100))\n","y = np.random.randint(-1, 1, size=(1000, 1))\n","num_iter = 0\n","for _ in batch_generator(X, y, 3):\n","    num_iter += 1\n","assert num_iter == (1000 // 3 + 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yJ9_3VfrkQMv","colab_type":"text"},"source":["# Задание 2. Обучите модель для классификации звезд\n","\n","Загрузите датасет из файла sky_data.csv, разделите его на train/test и обучите на нем нейронную сеть (архитектура ниже). Обучайте на батчах с помощью оптимизатора Adam, lr подберите сами, пробуйте что-то вроде 1e-2\n","\n","Архитектура:\n","\n","1. Dense Layer с relu активацией и 50 нейронами\n","2. Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте 50%) \n","3. BatchNorm\n","4. Dense Layer с relu активацией и 100 нейронами\n","5. Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте для разнообразия 50%)\n","6. BatchNorm\n","7. Выходной Dense слой c количеством нейронов, равному количеству классов\n","\n","Лосс - CrossEntropy."]},{"cell_type":"markdown","metadata":{"id":"qTd7VFMskQMw","colab_type":"text"},"source":["В датасете классы представлены строками, поэтому классы нужно закодировать. Для этого в строчке ниже объявлен dict, с помощью него и функции map превратите столбец с таргетом в целое число. Кроме того, за вас мы выделили признаки, которые нужно использовать."]},{"cell_type":"markdown","metadata":{"id":"MTMs6bU6kQMx","colab_type":"text"},"source":["### Загрузка и обработка данных"]},{"cell_type":"code","metadata":{"id":"Ci8mdz99kQMy","colab_type":"code","colab":{}},"source":["feature_columns = ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run', 'camcol', 'field']\n","target_column = 'class'\n","\n","target_mapping = {\n","    'GALAXY': 0,\n","    'STAR': 1,\n","    'QSO': 2\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRcIYVvUkQM2","colab_type":"code","outputId":"8c6b62aa-45d3-4a89-bc39-6470c22861f5","executionInfo":{"status":"ok","timestamp":1586246030358,"user_tz":-180,"elapsed":2450,"user":{"displayName":"Yury Yarovikov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gip8__BUAkkFW7zB1tjXwB7Y8uEezomM5ErVG2V=s64","userId":"05223355485824927663"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["data = pd.read_csv('https://drive.google.com/uc?id=1K-8CtATw6Sv7k2dXco1fL5MAhTbKtIH3')\n","data['class'].value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GALAXY    4998\n","STAR      4152\n","QSO        850\n","Name: class, dtype: int64"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"XQJyao1zoytL","colab_type":"code","colab":{}},"source":["data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"40-ivv77p9I2","colab":{}},"source":["# Extract Features\n","X = <YOUR CODE>\n","# Extract target\n","y = <YOUR CODE>\n","\n","# encode target with target_mapping\n","y = <YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3OkZT7HkQM7","colab_type":"text"},"source":["Нормализация фичей"]},{"cell_type":"code","metadata":{"id":"ynmXS7dMkQM8","colab_type":"code","colab":{}},"source":["# Просто вычтите среднее и поделитe на стандартное отклонение (с помощью пандас). Также преобразуйте всё в np.array\n","X = <YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEIewITCqo38","colab_type":"code","colab":{}},"source":["assert type(X) == np.ndarray and type(y) == np.ndarray, 'Проверьте, что получившиеся массивы являются np.ndarray'\n","assert np.allclose(y[:5], [1,1,0,1,1])\n","assert X.shape == (10000, 10)\n","assert np.allclose(X.mean(axis=0), np.zeros(10)) and np.allclose(X.std(axis=0), np.ones(10)), 'Данные не отнормированы'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VTcR3q0SkQNj","colab_type":"text"},"source":["Обучение"]},{"cell_type":"code","metadata":{"id":"m5AFbCY4kQNk","colab_type":"code","colab":{}},"source":["# Split train/test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","# Превратим данные в тензоры, чтобы потом было удобнее\n","X_train = torch.FloatTensor(X_train)\n","y_train = torch.LongTensor(y_train)\n","X_test = torch.FloatTensor(X_test)\n","y_test = torch.LongTensor(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZDCt0vtlkQNo","colab_type":"text"},"source":["Хорошо, данные мы подготовили, теперь надо объявить модель"]},{"cell_type":"code","metadata":{"id":"fI6ZqCaCkQNp","colab_type":"code","colab":{}},"source":["torch.manual_seed(42) \n","np.random.seed(42)\n","model = nn.Sequential(\n","    <YOUR CODE>\n",")\n","    \n","loss_fn = <YOUR CODE>\n","optimizer = <YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkUkeHfokQNs","colab_type":"text"},"source":["### Обучающий цикл"]},{"cell_type":"code","metadata":{"id":"41jYcT6AkQNt","colab_type":"code","colab":{}},"source":["def train(X_train, y_train, X_test, y_test, num_epoch):\n","    train_losses = []\n","    test_losses = []\n","    for i in range(num_epoch):\n","        epoch_train_losses = []\n","        for X_batch, y_batch in batch_generator(X_train, y_train, 500):\n","            # На лекции мы рассказывали, что дропаут работает по-разному во время обучения и реального предсказания\n","            # Чтобы это учесть нам нужно включать и выключать режим обучения, делается это командой ниже\n","            model.train(True)\n","            # Посчитаем предсказание и лосс\n","            # YOUR CODE\n","            \n","            # зануляем градиент\n","            # YOUR CODE\n","            \n","            # backward\n","            # YOUR CODE\n","            \n","            # ОБНОВЛЯЕМ веса\n","            # YOUR CODE\n","            \n","            # Запишем число (не тензор) в наши батчевые лоссы\n","            epoch_train_losses.append(# YOUR CODE)        \n","        train_losses.append(np.mean(epoch_train_losses))\n","        \n","        # Теперь посчитаем лосс на тесте\n","        model.train(False)\n","        with torch.no_grad():\n","            # Сюда опять же надо положить именно число равное лоссу на всем тест датасете\n","            test_losses.append(# YOUR CODE)\n","            \n","    return train_losses, test_losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"idGcIKlIth3D","colab_type":"code","colab":{}},"source":["def check_loss_decreased():\n","    print(\"На графике сверху, точно есть сходимость? Точно-точно? [Да/Нет]\")\n","    s = input()\n","    if s.lower() == 'да':\n","        print(\"Хорошо!\")\n","    else:\n","        raise RuntimeError(\"Можно уменьшить дропаут, уменьшить lr, поправить архитектуру, etc\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"cDyg5zMckQOX","colab_type":"code","colab":{}},"source":["train_losses, test_losses = train(# YOUR CODE) #Подберите количество эпох так, чтобы график loss сходился\n","plt.plot(range(len(train_losses)), train_losses, label='train')\n","plt.plot(range(len(test_losses)), test_losses, label='test')\n","plt.legend()\n","plt.show()\n","    \n","check_loss_decreased()\n","assert train_losses[-1] < 0.3 and test_losses[-1] < 0.3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UV1jaOM1SuTL","colab_type":"text"},"source":["### Вычислите accuracy получившейся модели на train и test"]},{"cell_type":"code","metadata":{"id":"dXqXflGcTBKS","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score\n","\n","model.eval()\n","train_pred_labels = #YOUR CODE: use forward\n","test_pred_labels = #YOUR CODE: use forward\n","\n","train_acc = accuracy_score(# YOUR CODE)\n","test_acc = accuracy_score(# YOUR CODE)\n","\n","assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n","assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n","\n","print(\"Train accuracy: {}\\nTest accuracy: {}\".format(train_acc, test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IB1XswA2kQOd","colab_type":"text"},"source":["# Задание 3. Исправление ошибок в архитектуре\n","\n","Только что вы обучили полносвязную нейронную сеть. Теперь вам предстоит проанализировать архитектуру нейронной сети ниже, исправить в ней ошибки и  обучить её с помощью той же функции train. Пример исправления ошибок есть в семинаре Григория Лелейтнера.\n","\n","Будьте осторожнее и убедитесь, что перед запуском train вы вновь переопределили все необходимые внешние переменные (train обращается к глобальным переменным, в целом так делать не стоит, но сейчас это было оправдано, так как иначе нам пришлось бы передавать порядка 7-8 аргументов).\n","\n","Чтобы у вас получилась такая же архитектура, как у нас, и ответы совпали, давайте определим некоторые правила, как исправлять ошибки:\n","\n","1. Если вы видите лишний нелинейный слой, который стоит не на своем месте, просто удалите его. (не нужно добавлять новые слои, чтобы сделать постановку изначального слоя разумной. Удалять надо самый последний слой, который все портит. Для линейных слоев надо что-то исправить, а не удалить его)\n","2. Если у слоя нет активации, то добавьте ReLU или другую подходящую активацию\n","3. Если что-то не так с learning_rate, то поставьте 1e-2\n","4. Если что-то не так с параметрами, считайте первый параметр, который появляется, как верный (т.е. далее в сети должен использоваться он).\n","5. Ошибки могут быть и в полносвязных слоях. \n","6. Любые другие проблемы решаются более менее однозначно, если же у вас есть серьезные сомнения, то напишите в беседу в телеграме и пинганите меня @runfme\n"]},{"cell_type":"markdown","metadata":{"id":"Un7PyM39kQOe","colab_type":"text"},"source":["Задача все та же - классификация небесных объектов на том же датасете. После исправления сети вам нужно обучить ее.\n","\n","**Ответ на задачу - средний лосс на тестовом датасете**"]},{"cell_type":"code","metadata":{"id":"3M9P67WekQOe","colab_type":"code","colab":{}},"source":["torch.manual_seed(42)   \n","np.random.seed(42)\n","# WRONG ARCH\n","model = nn.Sequential(\n","    nn.Dropout(p=0.5),\n","    nn.Linear(6, 50),\n","    nn.ReLU(),\n","    nn.Dropout(p=0.5),\n","    nn.Linear(100, 200),\n","    nn.Softmax(),\n","    nn.Linear(200, 200),\n","    nn.ReLU(),\n","    nn.Dropout(p=0.5),\n","    nn.Linear(200, 3),\n","    nn.Dropout(p=0.5)\n",")\n","\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters[:-2], lr=1e-100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T0HEx6vbkQOi","colab_type":"code","colab":{}},"source":["# RIGHT ARCH\n","torch.manual_seed(42)   \n","np.random.seed(42)\n","model = nn.Sequential(\n","    <YOUR CODE>\n",")\n","\n","\n","loss_fn = <YOUR CODE>\n","optimizer = <YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oGhmQg06gGiT","colab_type":"text"},"source":["### Обучите и протестируйте модель так же, как вы это сделали в задаче 2. Вычислите accuracy."]},{"cell_type":"code","metadata":{"id":"7SZv9yARkQOo","colab_type":"code","colab":{}},"source":["#YOUR CODE\n","\n","train_acc = <YOUR CODE>\n","test_acc = <YOUR CODE>\n","\n","\n","assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n","assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bUGWpT3MkQOr","colab_type":"text"},"source":["# Задание 4. Stack layers\n","\n","Давайте посмотрим, когда добавление перестает улучшать метрики. Увеличивайте блоков из слоев в сети, пока минимальный лосс на тестовом датасете за все время обучения не перестанет уменьшаться (20 эпох). \n","\n","Стоит помнить, что нельзя переиспользовать слои с предыдущих обучений, потому что они уже будут с подобранными весами.\n","\n","**Чтобы получить воспроизводимость и идентичный нашему ответ, надо объявлять все слои в порядке, в котором они применяются внутри модели. Это важно, если вы будете собирать свою модель из частей. Перед объявлением этих слоев по порядку напишите**\n","> torch.manual_seed(42)   \n","> np.random.seed(42)\n","\n","**При чем каждый раз, когда вы заново создаете модель, перезадавайте random seeds**\n","\n","**Опитимизатор - Adam(lr=1e-2)**\n"]},{"cell_type":"code","metadata":{"id":"JZzgn9y8kQOr","colab_type":"code","colab":{}},"source":["# МОДЕЛЬ ДЛЯ ПРИМЕРА, НА САМОМ ДЕЛЕ ВАМ ПРИДЕТСЯ СОЗДАВАТЬ НОВУЮ МОДЕЛЬ ДЛЯ КАЖДОГО КОЛИЧЕСТВА БЛОКОВ\n","model = nn.Sequential(\n","    nn.Linear(len(feature_columns), 100),\n","    nn.ReLU(),\n","    nn.Dropout(p=0.5),\n","    # Начало блока, который надо вставалять много раз\n","    nn.Linear(100, 100),\n","    nn.ReLU(),\n","    nn.BatchNorm1d(100),\n","    # Конец блока\n","    nn.Linear(100, 3)\n","    # Блока Softmax нет, поэтому нам нужно использовать лосс - CrossEntropyLoss\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"yYUngAvSkQOw","colab_type":"code","colab":{}},"source":["# Вы уже многое умеете, поэтому теперь код надо написать самому\n","# Идея - разделить модель на части.\n","# Вначале создать head часть как Sequential модель, потом в цикле создать Sequential модели, которые представляют\n","# из себя блоки, потом создать tail часть тоже как Sequential, а потом объединить их в одну Sequential модель \n","# вот таким кодом: nn.Sequential(header, *blocks, footer)\n","# Важная идея тут состоит в том, что модели могут быть частями других моделей)\n","<YOUR CODE>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hh5U-iUTgzxY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"In4h-bM_g0Vb","colab_type":"text"},"source":["## Задание 5. Сделайте выводы \n","Начиная с какого количества блоков минимальный лосс за время обучения увеличивается? Почему лишнее количество блоков не помогает модели? "]}]}